# -*- coding: utf-8 -*-
"""Placeholder bois ML4VA Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z40ejVTy1axCcQHtt_EjEoca679i0v4q
"""

from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
import seaborn

import os
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import pandas as pd

# Importing Virginia Beach Housing Data
url = "https://raw.githubusercontent.com/jjh5bc/ML4VA/master/Property_Sales.csv?token=AJ6FSTPP3O4WVSMEVDMGKFK5YIXLO"
vb_housing = pd.read_csv(url)
vb_housing.head(10)
#list(vb_housing)
vb_housing.head(10)

#from sklearn.model_selection import train_test_split
#x_attribs = ['GPIN', 'Street Address', 'Zip Code', 'Neighborhood', 'Land Value', 'Improvement Value', 'Sale Price', 'Sale Date']
#drop_attribs = ['Land Value', 'Street Address', 'Location 1']
#y_attribs = ['Total Value']
#train_set_x, test_set_x = train_test_split(vb_housing[x_attribs], test_size=0.2, random_state=42)
#train_set_y, test_set_y = train_test_split(vb_housing[y_attribs], test_size=0.2, random_state=42)
#train_set_x.head(10)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
vb_housing.hist(bins=50, figsize=(20,15))
# save_fig("attribute_histogram_plots")
plt.show()

dates = []
for i in range(507228):
  try:
    dates.append(int(vb_housing['Sale Date'][i].split('/')[-1]))
  except:
    dates.append(None)

vb_housing['dates'] = dates
vb_housing = vb_housing.drop('Sale Date',axis=1)
vb_housing = vb_housing.drop('Location 1',axis=1)
vb_housing = vb_housing.drop('Deed Page',axis=1)
vb_housing = vb_housing.drop('Deed Book',axis=1)
vb_housing = vb_housing.drop('Street Address',axis=1)
vb_housing = vb_housing.drop('Document Number',axis=1)
vb_housing = vb_housing.drop('Land Value',axis=1)
vb_housing.shape

list(vb_housing)

vb_housing = vb_housing.dropna()

sample_incomplete_rows = vb_housing[vb_housing.isnull().any(axis=1)]
sample_incomplete_rows

num_pipeline = Pipeline([
        # the imputer doesn't really matter in this case because there is no missing data
        ('std_scaler', StandardScaler()),
    ])
X_attribs = ['GPIN','Zip Code','Neighborhood','Improvement Value','Land USE (Y/N)','Sale Price','dates']
y_attribs = ['Total Value']
numerical_attribs = list(vb_housing.select_dtypes(include=[np.number]).drop("Total Value", axis=1))
category_attribs = ['Zip Code','Neighborhood','Land USE (Y/N)',]

full_pipeline = ColumnTransformer([
        ("num", num_pipeline, numerical_attribs),
        ("cat", OneHotEncoder(), category_attribs),
    ])

vb_housing.shape

vb_housing

import random
risks = []
for i in range(vb_housing.shape[0]):
  risks.append(random.randint(0,5))
vb_housing['risk'] = risks

vb_housing.head(10)

features = vb_housing[X_attribs]
features = full_pipeline.fit_transform(features)

features[0]

#train_set_X, test_set_X = train_test_split(features, test_size=0.2, random_state=42)
X_train, X_test = train_test_split(features, test_size=0.2, random_state=42)
# split only the charges (target value)
train_set_y, test_set_y = train_test_split(vb_housing[y_attribs], test_size=0.2, random_state=42)

y_train = num_pipeline.fit_transform(train_set_y)  # does not have categorical, only the charges
#X_train = full_pipeline.fit_transform(train_set_X) # has categorical
y_test = num_pipeline.fit_transform(test_set_y)    # does not have categorical, only the charges
#X_test = full_pipeline.fit_transform(test_set_X)

from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

lin_reg.predict(features[0])[0][0]

d = lin_reg.predict(features[0])
num_pipeline.inverse_transform(d)

def econ_loss(feature_set, year):
  cost = num_pipeline.inverse_transform(lin_reg.predict(features[feature_set]))[0][0]
  risk = risks[feature_set]
  if year > risk:
    return cost
  return 0
econ_loss(3,4)

X_test.shape

X_train.shape

from sklearn.metrics import mean_squared_error
lin_predictions = lin_reg.predict(X_test)

lin_reg_mse = mean_squared_error(y_test, lin_predictions)
lin_reg_rmse = np.sqrt(lin_reg_mse)
lin_reg_rmse

lin_reg.score(X_train, y_train)

from sklearn.model_selection import cross_val_score
scores = cross_val_score(lin_reg, X_train, y_train,
                         scoring="neg_mean_squared_error", cv=10)
tree_rmse_scores = np.sqrt(-scores)

np.mean(tree_rmse_scores)

from sklearn.ensemble import RandomForestRegressor

forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)
forest_reg.fit(X_train, y_train)

from sklearn.metrics import mean_squared_error
rf_predictions = forest_reg.predict(X_test)

rf_mse = mean_squared_error(y_test, rf_predictions)
rf_rmse = np.sqrt(rf_mse)
rf_rmse

from sklearn.model_selection import cross_val_score
scores = cross_val_score(forest_reg, X_train, y_train,
                         scoring="neg_mean_squared_error", cv=10)
tree_rmse_scores = np.sqrt(-scores)
tree_rmse_scores

"""# Visualization of coordinates using geopandas"""

!pip3 install geopandas
import descartes
import geopandas as gpd
from shapely.geometry import Point, Polygon

c = 0
points = []
for i in range(507228):
  try:
    points.append(vb_housing['Location 1'][i].split('\n')[2])
  except:
    c = c + 1
c

latitude = []
longitude = []
for i in range(len(points)):
  latitude.append(float(points[i].strip('(').strip(')').split()[0].strip(',')))
  longitude.append(float(points[i].strip('(').strip(')').split()[1]))

!SHAPE_RESTORE_SHX=YES fio info City_of_Virginia_Beach_Boundary.shp
!SHAPE_RESTORE_SHX=YES fio info City_Property.shp
vb_map = gpd.read_file('City_of_Virginia_Beach_Boundary.shp')
vb_better_map = gpd.read_file('City_Property.shp')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
fig,ax = plt.subplots(figsize=(15,15))
vb_better_map.plot(ax=ax)

data = {'Longitude':longitude,'Latitude':latitude}
df = pd.DataFrame(data)
geometry = [Point(xy) for xy in zip(df['Longitude'], df['Latitude'])]
crs = {'init':'epsg.4326'}
geo_df = gpd.GeoDataFrame(df,crs=crs,geometry=geometry)
geometry[:3]

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
fig,ax = plt.subplots(figsize=(15,15))
vb_map.plot(ax=ax, alpha=0.4, color='grey')
geo_df[geo_df['Longitude']!=0].plot(ax=ax, markersize=20, color='blue', marker='o',label='neg')
plt.legend(prop={'size':15})

"""![alt text](https://github.com/ur6yr/ML4VA/raw/master/slr.png)"""